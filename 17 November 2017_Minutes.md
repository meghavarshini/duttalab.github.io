## Laptop Requirements


Laptop requirement: Intel Core i5: Macbook may not be an option. Also, additional systems required for the ultrasound machine, and possibly for running the ultrasound and eye-tracking machine in a synchonised manner.#3 proposed experiments:## Experiment 1:Cross-spliced words (to be provided by ID)
In Malayalam, coarticulatory resistance: Alveolar>Retroflex>DentalOdd, because alveolars are articulatorily least complex. This is best explained by the fact that alveolars in Malayalam have the least neighborhood density due to the constraints imposed by the language upon their occurrence.The articulation of a **V<sub>1</sub>CV<sub>2</sub>** takes 100ms.When speakers gaze at an alveolar, more resistance = slowest reaction.   In this experiment, V1 will have the same quality as V2.
<BR> Burst: When stop released, shape of the tongue and oral cavity tells us what the stop was.

**RM:** Triggers must be semantically derived because if they don't triffer, paradigm won't work. Unless the objective is to show 'unnatural' contexts.

## Experiment 2:
Benchmark: 200ms (movement- anticipatory)
Ensure that there is enough length. _Gradient_ through Praat

Persevatory: 25% V<sub>2</sub>   alveolar, rest retroflex. 
Manipulate V<sub>2</sub> <br>
Gaze shifts as V<sub>2</sub> makes an appearance.

**ID'S Experiment:**
Dental/Retroflex: Format transition, vowel target met at 25%-30%
But alveolar won't let target to _____ met even at 50%

Geminates- 150ms as is

Burst +25% verb pointing towards alveolar

## Experiment 3:
Novel stimuli
Pre-testing- vary frequency. Even though you saw more alveolar but are slow still _coarticulatory resistence_
**RM:** Since semantics is not a concern, maybe deal with only one phonology?
After Exp. 1 & 2, semantics will not be an issue.<br>
**RM:** Eye movement to object, names related with phonological links, or competitors (minimal pairs)
Subtle time - cases <br>
Visible--   \>30 degree change in eye movement <br>
Linguistic cases drive even faster (100ms) <br>
How much input is enough?

**ID:** Variable cross-splice

**RM:** At this point in time, we can't say how much noise we would get. <br>
Our comprehension is slower than tracking frame rate-- 100ms(upto 200ms)

Fillers--  50-50 <br>
To break strategy
/ *Task is central to paradign, but is orthogonal <br>
Filler trials to break strategy <br>
Task or no task? (depends on psychological needs, trial type and time <br>
Time and visual together or present after gap of 500-1000ms? <br>
Slower (100ms) for semantics appraisal. <br>
Has generated phonological form. <br>

How many quadrants? 3 or 4?
4-- fixation not measured, too many offsets <br>

**RM:** 30-40 subjects, Why not meaningful words? <br>
If both are novel. . . 
<br>
**How much duration do we need for visual paradigm?** 

**RM:** Controlled consition, without splicing needed.
**ID:** Complexity is what has not been worked on. Greater delay in alveolar?

Visual world plot: analyse w.r.t mixed effects

**ID:** Vowel also changes. High vowel will show less coarticulatory resistence. Ex. /a/ won't allow tongue to go up at all.

**RM:** Printed words are an option. But alveolars will give speakers an idea (Malayalam diacritic is a problem?)

<u> If semantics directly activated, better idea </u> <br>
 **ID:** Technically, minimal contrast but linguistic distribution is messed up. No singleton, no voiced component, so 25% cases left. Very restricted <br>
Most languages may have an alveolar stop, but frequency? <u> Neighborhood Density low </u> <br>
Text corpus large,, so lexical frequency will be controlled very well. 

**RM:** Ratings, on the same criteria, distractors must receice low ratings. <br>
Totally random, unrrelated. But lexical frequency must be high. (pictures: name agreement taken)

**ID:** Synthetic stimuli will be restricted. At EFLU, only acceptible recordings will be used. Forced choice or gradient is fine. <br>
Coarticulatory effects known to be non-contiguous (V<sub>3</sub> affecting V<sub>1</sub>)<br>
Most have argued-- <br>
*Anticiparoty or cognitive effect <br>
*Persivatory or biochemical effect <br>

**RM:** Linguistic anticipation works because of perception. <br>
What leads to anticipation? <br>
delay, non-native speech, absence of familiarity-- <br>
How do we understand link between production and perception?

What if we take Malayalam speakers who are not from Kerala? <br>
Production studies with eye-tracking

## Ultrasound Machine and Eye-Tracking

No obstruction <br>
Simultaneous data in production studies

 Naming tasks. Competitors?
 
 **ID:** Persivatory also cognitive. In tone productions (high vs flat) <br>
 If CV<SUB>1</SUB> affects CV<SUB>2</SUB>, then this is proved.
 (Mandarin) <br>
 Residual planning of CV<SUB>1</SUB> affects CV<SUB>2</SUB> (impact implier that it is cognitive).
 
 **RM:** Sensory or motor explanations <br>
 Multimodal = Multisensory <br>
 'tone sandhi' <br>
 Articulatory phonology? <br>
 Simulation is key to perception, whether explicit or implicit. 
 <br> *EEG?
 
 (Classical Tamil)
 
 Assamese-- Only and only alveolars, every coronal maps to it.
 
 Alveolar stop coarticulates freely with all vowels.
 
 Syncing eye-tracking and ultrasound.
 
 Need a box to sync-parallel port
 
 TTL trigger-- experimentor
 
 Electro ocholograph?
 
 Speed of ultrasounds-- 120fps
 
 What about acoustically treated conditions?
 
 Speed of both devices must be considered.
 
 Edge Tracker:
<br>
ML-- Needed for getting around the problem of shadowing during reflection


Ethics Committee-- Questions will be asked <br>
1. Ratings for acceptance <br>
2. Fillers- similar syllables, similar graphemes <br>
Two groups of people, randomly assigned trials and fillers No mixing. Comparing natural and synthetic speech <br>
One group assigned natural speech, the other natural+manipulated
 **R.M:** ID must meet Vandana Singh. October(when JRFs joined) to be treated as when work started. 
 


 
 

 


